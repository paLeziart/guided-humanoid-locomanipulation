<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A framework for teaching humanoid robots to imitate humans doing useful tasks by training policies for tracking human motion references.">
  <meta name="keywords" content="Reinforcement Learning, Imitation Learning, Humanoid loco-manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Expert-Guided Imitation for Learning Humanoid Loco-Manipulation from Motion Capture</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/laasicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Expert-Guided Imitation for Learning Humanoid Loco-Manipulation from Motion Capture</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://rohanpsingh.github.io/">Rohan P. Singh</a><sup>*,1</sup>,</span>
            <span class="author-block">
              <a href="https://paleziart.github.io/">Pierre-Alexandre Leziart</a><sup>*,1</sup>,</span>
            <span class="author-block">
              <a href="">Masaki Murooka</a><sup>1</sup>,
            </span> </br>
            <span class="author-block">
              <a href="">Mitsuharu Morisawa</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Eiichi Yoshida</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Fumio Kanehiro</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup> Equal contribution,</span>
            <span class="author-block"><sup>1</sup> CNRS-AIST JRL (Joint Robotics Laboratory), Tsukuba, Japan,</span>
            <span class="author-block"><sup>2</sup> Tokyo University of Science, Tokyo, Japan</span>
          </div>


           <!-- TODO UPDATE LINKS -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/pdfs/singh2025_guidedHumanoidLocoManipulation.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>
              <!--<span class="link-block">
                <a href="https://arxiv.org/abs/2403.18765"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>-->
              <!-- Video Link. -->
              <!--<span class="link-block">
                <a href="https://www.youtube.com/watch?v=crWoYTb8QvU"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/rohanpsingh/LearningHumanoidWalking"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Dataset Link. -->
              <!-- 
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              -->
            </div>

          </div>
          We intend to release the framework for this work into the above Github code repository.<br>
          This work has been accepted for presentation at the <b>CoRL 2025 workshop on Open-Source Hardware in the Era of Robot Learning</b>, and at the <b>Humanoids 2025 workshop on Sim-to-Real Transfer for Humanoid Robots</b>.
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video poster="" id="steve" autoplay controls loop playsinline height="100%">
            <source src="./static/videos/singh2025_video.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite significant advances in bipedal locomotion, enabling humanoid robots to perform general whole-body tasks through meaningful interaction with their environments remains a challenging open problem. While deep reinforcement learning (RL) has recently demonstrated impressive results in dynamic walking &mdash; even on complex and unpredictable terrain &mdash; real-world utility demands that humanoids go beyond locomotion to execute task-oriented behaviors.
          </p>
          <p>
            In this work, we propose a framework for teaching humanoid robots to imitate humans doing useful tasks by training policies for tracking human motion references.  Our approach leverages high-quality in-house motion capture (MoCap) data, from which we perform kinematic retargeting to project human trajectories onto a humanoid platform. Crucially, we adopt a hybrid learning paradigm: the policy is trained to track upper-body and root motions from the MoCap data, and receives additional supervision from a pre-trained omnidirectional walking expert. This expert guidance, implemented via a Behavior Cloning (BC) objective, ensures that leg motion respects dynamics and kinematic constraints of the humanoid. We train policies entirely in simulation and successfully transfer them to a real humanoid robot. We validate our method on a box loco-manipulation task, demonstrating effective sim-to-real transfer and marking a step toward more capable, task-driven humanoid behavior.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="column is-full-width">
      
      <div class="content has-text-justified">
        <p>
          Our objective is to develop a methodology that enables humanoid robots to learn
          loco-manipulation behaviors directly from human motion demonstrations. To this
          end, we propose a framework that combines motion capture, inverse kinematics (IK),
          and reinforcement learning (RL) with an auxiliary Behavior Cloning (BC) loss term
          to achieve motion imitation while maintaining dynamic feasibility on humanoid
          platforms.  
        </p>
      </div>

      <h3 class="title is-3">Motion capture recording</h3>
      <div class="content has-text-justified">
        <p>
          The pipeline begins with the collection of reference motion data in-house by having a human subject perform
          the loco-manipulation task while wearing a full-body motion capture suit. 
          This includes walking towards a box placed on a table, picking it up, then walking to another table to drop it down. 
          We record both the 3D trajectories of body markers and the corresponding skeletal
          motion. We also record contact forces through sensors placed on the hands and on the bottom surface of the box for accurate identification of contact events during interaction.
        </p><br>
        <div class="columns is-centered has-text-centered">
          <video id="teaser" autoplay muted loop controls playsinline width="900">
            <source src="./static/videos/motion_capture_recording.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 class="subtitle has-text-justified">
          <i>Fig 1: Recording a single human motion reference using a motion capture system.</i>
        </h4>
      </div>

      <h3 class="title is-3">Motion retargeting with IK</h3>
      <div class="content has-text-justified">
        <p>
          The kinematic retargeting of the collected MoCap trajectory from a human skeleton
          to a humanoid robot is formulated as an optimization-based inverse kinematics through a constrained quadratic programming problem. The objective function
          minimizes the weighted sum of squared errors between the 3D positions and orientations
          of key end-effectors (hands and feet) as well as the pose of the torso,
          and the head. This formulation allows for smooth tracking of human motion while preserving
          the structural characteristics of the original trajectory.
        </p><br>
        <div class="columns is-centered has-text-centered">
          <video id="teaser" autoplay muted loop controls playsinline width="900">
            <source src="./static/videos/IK_retargeting.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 class="subtitle has-text-justified">
          <i>Fig 2: Visualization of the retargeting with both human and robot skeletons.</i>
        </h4>
      </div>

      <h3 class="title is-3">Training an expert walking policy</h3>
      <div class="content has-text-justified">
        <p>
          Directly mimicking full-body trajectories including walking
          movements is infeasible due to the substantial dynamic and morphological differences
          between humans and humanoid robots. In particular, the discrepancy in limb proportions 
          and joint constraints often leads to violations of dynamic stability when attempting to 
          directly replicate human walking patterns. Our early sim-to-real experiments showed that 
          the robot struggles to make stable foot contacts with the floor while making unrealistically 
          long strides. Furthermore, tuning IK parameters to enforce both kinematic accuracy and 
          plausible contact dynamics such as maintaining foot orientation is labor-intensive and not scalable. 
          Thus we train an expert bipedal walking policy by adapting for H1 the approach presented in [1] [2].
        </p><br>
        <div class="columns is-centered has-text-centered">
          <video id="teaser" autoplay muted loop controls playsinline width="900">
            <source src="./static/videos/expert_policy.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 class="subtitle has-text-justified">
          <i>Fig 3: The expert policy is trained with dynamics randomization, random pushes and small terrain bumps.</i>
        </h4>
        <p>
          [1] R. P. singh, Z. Xie, P. Gergondet, and F. Kanehiro, “Learning bipedal 
          walking for humanoids with current feedback,” IEEE Access, vol. 11, 
          pp. 82 013-82 023, 2023.<br>
          [2] R. P. Singh, M. Morisawa, M. Benallegue, Z. Xie, and F. Kanehiro, 
          “Robust humanoid walking on compliant and uneven terrain with 
          deep reinforcement learning,” in 2024 IEEE-RAS 23rd International 
          Conference on Humanoid Robots (Humanoids). IEEE, 2024, pp. 497-504. 
        </p>
      </div>


      <h3 class="title is-3">Hybrid motion tracking with RL and BC</h3>
      <div class="content has-text-justified">
        <p>
          We implement a teacher-student supervision through a behavior cloning objective, guiding the
          student policy to match the expert's leg actions. In parallel, we leverage RL to train the 
          upper body to imitate the human motion reference. This hybrid 
          approach allows the student policy to benefit from high-level human demonstrations
          while leveraging the robustness and stability of the expert locomotion policy,
          resulting in a coherent whole-body behavior that successfully integrates walking
          and manipulation.
        </p><br>
        <div class="columns is-centered has-text-centered">
          <video id="teaser" autoplay muted loop controls playsinline width="900" >
            <source src="./static/videos/locomanipulation_simu.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 class="subtitle has-text-justified">
          <i>Fig 4: We train 3 policies respectively for pick-up, drop-off and return to the origin. 
             When one policy has finished its task, we automatically switch to the next one.</i>
        </h4>
      </div>

      <h3 class="title is-3">Real-world deployment</h3>
      <div class="content has-text-justified">
        <p>
          The robot achieves 
          a full loco-manipulation cycle by walking toward the box, picking it up to drop it off on 
          another table, then going back to its starting position. This is done in one go by automatically 
          switching between policies when the phase clock signal reaches its final value. The cycle can 
          be repeated on-the-fly by placing the box back on the first table while the robot is returning 
          to the starting position. This successful deployment indicates that the domain randomization 
          we used was effective for crossing the sim-to-real gap. 
        </p><br>
        <div class="columns is-centered has-text-centered">
          <video id="teaser" autoplay muted loop controls playsinline width="900" >
            <source src="./static/videos/locomanipulation_real.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 class="subtitle has-text-justified">
          <i>Fig 5: Full loco-manipulation cycle by switching policies online. The cycle is repeated
            by switching back to the first policy once the robot is back at the initial position.
          </i>
        </h4>
      </div>

      <h3 class="title is-3">Extension to long distance loco-manipulation</h3>
      <div class="content has-text-justified">
        <p>
          Even if the policy was trained with a single human motion recording that demonstrated
          a pick-and-place on a short distance, we generalize loco-manipulation over long distances.
          To do so, we leverage a 2D Dubins planning algorithm to generate paths along which fake target 
          positions will be set to sequentially lead the robot to the real pick-up and drop-off locations.
          That way the target positions given to the policy remains in-distribution.
        </p><br>
        <div class="columns is-centered has-text-centered">
          <video id="teaser" autoplay muted loop controls playsinline width="900" >
            <source src="./static/videos/locomanipulation_long_distance.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 class="subtitle has-text-justified">
          <i>Fig 6: Due to the box position, the robot cannot directly handle it as a target as it is way
            out of distribution. Instead, we use the Dubins planner to generate intermediate targets so
            that the robot moves past the box before looping back.
          </i>
        </h4>
      </div>

    </div>
  </div>
</section>









<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a> --> <!-- TODO LINK -->
      <a class="icon-link" href="https://github.com/paLeziart/guided-humanoid-locomanipulation" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a> for sharing their template.
          </p>
          <p>
            You are free to borrow the <a href="https://github.com/paLeziart/guided-humanoid-locomanipulation">source code</a> <!-- TODO LINK -->
            of this website, we just ask that you link back to this page in the footer, as well as to
            <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>